\newpage
\subsection{Artificial Neural Networks}
Artificial Neural Networks (ANNs) are function approximators loosely inspired by nervous systems. They have been shown to be able
to approximate any continuous function with any desired accuracy \cite{universality_formal,universality_informal}.

ANNs consist of nodes, also called neurons, connected by directed links (see Figure \ref{feedforward}).
A node is either an input node that receives external input data, an output node which sends out a final value computed
by the network or a hidden node, a node that exists somewhere between the input and output nodes. Each node receives signals, either
as the initial input or as signals from other nodes. Each link is associated with a weight which inhibits or excites the signal
passing over it. The nodes sum the incoming weighted signals, calculating a net input signal. A function is applied to the net input
signal to generate an output signal (see Figure \ref{neuron}). The function is referred to as an activation function and regulates the strength of the output
signal given the net input signal. The signal is propagated through the network until it reaches the final output node or nodes.


\begin{figure}[htb]
    \begin{mdframed}
        \begin{subfigure}[b]{0.5\textwidth}
            \centering
            \resizebox{0.7\textwidth}{!}{\input{resources/tex/feedforward.tex}}
            \caption{ANN example.}
            \label{feedforward}
        \end{subfigure}
        \begin{subfigure}[b]{0.5\textwidth}
            \centering
            \resizebox{0.9\textwidth}{!}{\input{resources/tex/neuron.tex}}
            \caption{Higlighted path from (a).}
            \label{neuron}
        \end{subfigure}
    \end{mdframed}
    \caption{(a) A feed-forward ANN. (b) Illustration of what happens inside each non-input node of the network; input
                 signals are weighted and summed forming a net input signal to which an activation function is applied.}
\end{figure}

Different algorithms exist to update parameters of the network, such as the weights of the
links, as to improve the output for different inputs. The process in which the parameters of
the network are optimised is referred to as training. For instance, supervised learning algorithms use input-output
examples to train the network. The input is fed into the network and the output is compared
to the expected output for the example. The difference is used to update the weights in the network as to decrease
the error. After training with a sufficient number of different examples, the network might generalise and provide
correct outputs for previously unseen examples.

For a better introduction to ANNs, see for example \cite{compint}.