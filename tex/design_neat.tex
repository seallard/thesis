\section{Implementation of NEAT}

I implemented NEAT in Python based on the original C++ version. To verify the functionality of my implementation and compare it to
the original one \cite{neat_main}, the performance on XOR was tested. Data was collected from 100 runs (see Table \ref{xor_verification}).
Each run was terminated once a network that solved XOR was found or the number of network evaluations exceeded 20 000.
The parameters used can be found in appendix \ref{parameter_values}.
\begin{table}[H]
    \centering
    \sisetup{table-format = 3.2}
    \begin{tabular}{lSS}
    \toprule
    Statistic & \multicolumn{1}{l}{Implementation} & \multicolumn{1}{l}{Original \cite{neat_main}} \\
    \midrule
    \rowcolor[gray]{.9} Mean evaluations & 4196 & 4755\\
    Standard deviation & 2367 & 2553\\
    \rowcolor[gray]{.9} Mean hidden nodes & 2.98 & 2.35\\
    Standard deviation & 1.35 & 1.11\\
    \rowcolor[gray]{.9} Mean links & 12.71 & 7.48\\
    Standard deviation & 4.31 & NaN\\
    Failures & 0 & 0\\
    Worst performance (evaluations) & 12153 & 13459 \\
    Minimal structures found & 12 & 22\\
    \bottomrule
    \end{tabular}
    \caption{Comparison of the performance on XOR with the original NEAT implementation. A population size of 150 networks was used.
             The statistics were calculated over 100 runs.}
    \label{xor_verification}
\end{table}
The difference in the mean number of evaluations was not significant at the $0.05$ level ($p=0.11$).
The networks found by my implementation seem to be larger on average.
The latter might be due to the higher mutation rates I had to use for the addition of nodes and links
to obtain satisfactory results.
