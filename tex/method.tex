\section{Method}
Most research on variations of novelty search has been done in the domain of maze solving. Mazes are useful
since they allow for the construction of tasks of varying deceptiveness. If the objective function is
based on the distance to the end of the maze, simply following its gradient might trap the agent in
dead-ends. The maze can be seen as an abstraction for difficult problems in which the fitness
landscape is deceptive.

\subsection{Maze navigation task}
In maze navigation, a simulated robot must solve a maze within a limited number of time steps.
The robot is controlled by a neural network which, given the readings from the robots sensors,
outputs two forces adjusting the robots linear and angular velocity.

The robot has six rangefinder sensors which measure the distance to walls. If a wall occurs within the sensors
direction and maximum range, the distance is returned. It also has four radar sensors which return binary
values indicating whether the end-point is directly reachable within their field of view.

Two mazes are used to compare the novelty search variants (see Figure \ref{mazes}) similar to the ones in \cite{novelty_alone}.
Any robot which navigates within 5 units of the end point is classified as having solved the maze.

\begin{figure}[H]
    \captionsetup[subfigure]{justification=centering}
    \centering
    \begin{mdframed}
        \begin{subfigure}[b]{0.45\textwidth}
            \centering
            \hspace*{2em}\scalebox{0.3}{\input{resources/mazes/medium.pgf}}
            \caption{Medium.}
        \end{subfigure}
        \begin{subfigure}[b]{0.5\textwidth}
            \centering
            \hspace*{5em}\scalebox{0.3}{\input{resources/mazes/hard.pgf}}
            \caption{Hard.}
        \end{subfigure}
    \end{mdframed}
    \caption{The robot must navigate from the green point to the red in order to solve the maze.
             (b) is more deceptive than (a).}
    \label{mazes}
\end{figure}

\subsection{Fitness and novelty metric}
The fitness function is defined as $f = b - d$ where $b$ is a constant ensuring the fitness stays positive
and $d$ is the distance from the robots final position to the maze end-point after an evaluation.
The novelty metric is defined as the distance between the robots different end-positions in the maze.
These metrics have consistently been used in previous studies on novelty search.

\subsection{Combinations}
The idea behind both of the studied combinations is to use novelty search in order to introduce diversity
when the search algorithm seems to have converged prematurely on local optima.

\subsubsection{Dynamic novelty linearisation}
In dynamic novelty linearisation, as proposed in \cite{novelty_not_enough}, a weighted sum of novelty and fitness is used:
\[
    score(i) = (1-\rho) \cdot \overline{fitness}(i) + \rho \cdot \overline{novelty}(i)
\]
where $\rho \in [0,1]$ and the fitness and novelty score are normalised according to:
\[
    \overline{fitness}(i) =  \frac{fit(i) - fit_{min}}{fit_{max} - fit_{min}}
\]


The weights are updated during runtime such that they are proportional to the number of generations since a solution of
higher fitness was found.

\subsubsection{Novelty injection}
In novelty injection, the novelty metric is used only if stagnation is detected. That is, if no solution is found with a
higher fitness within some threshold number of generations, the fitness metric is swapped for novelty for a fixed
number of generations. The idea is that stagnation of the maximum observed fitness might signal
premature convergence on local optima.

\subsection{Experimental design}
Each variant is evaluated over $30$ runs for each maze, each run lasting for $100 000$ evaluations.
To provide a baseline comparison, the experiment is run with pure fitness and novelty. To see how
the proposed combinations compare to existing ones, it is repeated with a fixed 50-50 weighted sum
of fitness and novelty which has been shown to perform well on the maze task \cite{ns_study}.
